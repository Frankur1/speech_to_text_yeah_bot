import os
import asyncio
import ffmpeg
from aiogram import Bot, Dispatcher, types
from aiogram.enums import ParseMode
from aiogram.filters import CommandStart
from aiogram.client.default import DefaultBotProperties
from openai import OpenAI
from dotenv import load_dotenv

# === –ó–∞–≥—Ä—É–∂–∞–µ–º .env ===
load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TEMP_DIR = "downloads"

os.makedirs(TEMP_DIR, exist_ok=True)

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±–æ—Ç–∞ ===
bot = Bot(
    token=BOT_TOKEN,
    default=DefaultBotProperties(parse_mode=ParseMode.HTML)
)
dp = Dispatcher()
client = OpenAI(api_key=OPENAI_API_KEY)


# === –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ ===
async def extract_audio(video_path: str, output_path: str):
    stream = ffmpeg.input(video_path)
    stream = ffmpeg.output(stream, output_path, ac=1, ar=16000)
    ffmpeg.run(stream, overwrite_output=True, quiet=True)
    return output_path


# === –†–∞—Å–ø–æ–∑–Ω–∞—ë–º —Ä–µ—á—å —á–µ—Ä–µ–∑ OpenAI ===
def transcribe_audio(audio_path: str) -> str:
    with open(audio_path, "rb") as audio_file:
        transcription = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            response_format="text"
        )
    return transcription


# === –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start ===
@dp.message(CommandStart())
async def start(message: types.Message):
    await message.answer(
        "üé• <b>–ü—Ä–∏–≤–µ—Ç!</b>\n\n"
        "–û—Ç–ø—Ä–∞–≤—å –º–Ω–µ –≤–∏–¥–µ–æ, –∞—É–¥–∏–æ –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ ‚Äî –∏ —è –ø—Ä–µ–≤—Ä–∞—â—É —Ä–µ—á—å –≤ —Ç–µ–∫—Å—Ç ‚ú®"
    )


# === –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –º–µ–¥–∏–∞ ===
@dp.message(lambda m: m.video or m.audio or m.voice or m.video_note or (m.document and m.document.mime_type and m.document.mime_type.startswith("video")))
async def handle_media(message: types.Message):
    await message.answer("üéß –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–∞–π–ª... —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ ‚è≥")

    try:
        file = message.video or message.audio or message.voice or message.video_note or message.document
        file_info = await bot.get_file(file.file_id)
        file_path = f"{TEMP_DIR}/{file.file_unique_id}"
        await bot.download_file(file_info.file_path, file_path)

        audio_path = f"{file_path}.wav"
        await extract_audio(file_path, audio_path)

        text = await asyncio.to_thread(transcribe_audio, audio_path)

        if text.strip():
            await message.answer(f"üìù <b>–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:</b>\n\n{text}")
        else:
            await message.answer("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å –≤ —ç—Ç–æ–º —Ñ–∞–π–ª–µ.")
    except Exception as e:
        await message.answer(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: <code>{e}</code>")
    finally:
        for f in [file_path, audio_path]:
            if os.path.exists(f):
                os.remove(f)


# === –ó–∞–ø—É—Å–∫ ===
async def main():
    print("‚úÖ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ...")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
